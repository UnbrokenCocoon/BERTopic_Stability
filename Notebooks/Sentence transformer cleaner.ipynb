{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1oCK_2MjZkMNMnyh-PgTCH8z5yrVRUGkF","authorship_tag":"ABX9TyNdPajoWK0mXZdvB4Rw44ym"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e7c79f659ce94de99c6400ae663641b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_778f96ae504949348dd269472eabc2cb","IPY_MODEL_4f1be87bb28b4e5cb7731207c571664a","IPY_MODEL_dc2aa3e977ee481eb4768bf17463ca8f"],"layout":"IPY_MODEL_59bc5bad310d46e994225735f0095231"}},"778f96ae504949348dd269472eabc2cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88785cb4f569413888f40526ba644c68","placeholder":"​","style":"IPY_MODEL_6df24f54d8934d3c9b23907ed21cf907","value":"Batches: 100%"}},"4f1be87bb28b4e5cb7731207c571664a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e07f56282d154857a11a98c3244d2d04","max":3778,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7fb715647f44a2593052f6ec1027f5b","value":3778}},"dc2aa3e977ee481eb4768bf17463ca8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e59c63c837f443f8037167f6149289a","placeholder":"​","style":"IPY_MODEL_7fb857c36cac401791f37a0932a51dc2","value":" 3778/3778 [1:57:54&lt;00:00,  1.09s/it]"}},"59bc5bad310d46e994225735f0095231":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88785cb4f569413888f40526ba644c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6df24f54d8934d3c9b23907ed21cf907":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e07f56282d154857a11a98c3244d2d04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7fb715647f44a2593052f6ec1027f5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e59c63c837f443f8037167f6149289a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fb857c36cac401791f37a0932a51dc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install sentence_transformers nltk\n","import nltk\n","nltk.download('punkt_tab')\n","# This notebook prepares your text corpus for BERTopic by performing sentence splitting, optional text normalisation, and embedding generation using SentenceTransformers.\n","# It ensures the data is in the correct format for downstream topic modelling."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSFYdp45JD9E","executionInfo":{"status":"ok","timestamp":1746444321946,"user_tz":-60,"elapsed":104356,"user":{"displayName":"tom compton","userId":"11608738456980900557"}},"outputId":"d61873c6-f7f3-407d-8a6a-e633393aa110"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.51.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.15.2)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.30.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.4.26)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"markdown","source":["We will begin with a generative example. This is an example of text we want to chunk into sentences, but is lacking punctuation. Using this small scale example, we will understand how the pipeline works"],"metadata":{"id":"y_ZI_36zI2hO"}},{"cell_type":"code","source":["import re\n","def clean_text(text):\n","    text = re.sub(r'\\d+', '', text)               # Remove digits\n","    text = re.sub(r'\\b\\d+\\b', '', text)\n","    text = re.sub(r'[^\\w\\s]', '', text)           # Remove punctuation (grammar)\n","    text = re.sub(r'\\s+', ' ', text).strip()      # Remove extra whitespace/newlines\n","    return text.lower()"],"metadata":{"id":"6sUqqMV9Rsak"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FTOR7c4v6SVz"},"outputs":[],"source":["import nltk\n","text = \"\"\"\n","This is a sample paragraph. It includes several sentences, some of which are short.\n","However, others may be longer or more complex. Therefore, we aim to split this text\n","into clean, readable chunks using punctuation and connectives.\n","\"\"\"\n","\n","# Define strong connectives to split at (you can expand this)\n","connectives = r'\\b(?:however|therefore|moreover|but|although|yet|because|so)\\b'\n","\n","# Include major punctuation: comma, semicolon, colon, period, dash, newline, question mark, exclamation\n","split_regex = r'[;,\\.\\?!:\\-\\–\\n]+' + '|' + connectives\n","\n","# Split the text\n","texts = re.split(split_regex, text, flags=re.IGNORECASE)\n","cleaned_texts = [clean_text(t) for t in texts if len(t.strip()) > 0]\n"]},{"cell_type":"code","source":["test_sentences =[]\n","results = []\n","buffer = \"\"\n","for i in cleaned_texts:\n","  buffer += i + \" \"\n","  words = nltk.word_tokenize(buffer)\n","  length = len(words)\n","  if length >= 9:\n","    results.append(length)\n","    buffer.strip()\n","    test_sentences.append(buffer)\n","    buffer = \"\"\n","\n","\n","if buffer.strip():\n","    test_sentences.append(buffer.strip())\n","print(test_sentences)"],"metadata":{"id":"poNicsY0MfFO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This output will inform us of how effective this pipeline is\n","# We want almost none in too_short or too_long\n","# Average length should be around 9-13 to be even. But higher is fine.\n","import numpy as np\n","\n","print(\"Total chunks:\", len(results))\n","print(\"Average length:\", round(np.mean(results),2))\n","print(\"Median length:\", np.median(results))\n","print(\"Max length:\", max(results))\n","print(\"Min length:\", min(results))\n","\n","too_short = sum(r < 9 for r in results)\n","too_long = sum(r > 40 for r in results)\n","print(f\"Chunks < 9 words: {too_short}\")\n","print(f\"Chunks > 20 words: {too_long}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjBW5ViM7cov","executionInfo":{"status":"ok","timestamp":1746448989304,"user_tz":-60,"elapsed":62,"user":{"displayName":"tom compton","userId":"11608738456980900557"}},"outputId":"a446b86f-9478-4417-c612-0ad3eb0ee2b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total chunks: 120882\n","Average length: 12.84\n","Median length: 12.0\n","Max length: 53\n","Min length: 9\n","Chunks < 9 words: 0\n","Chunks > 20 words: 27\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import shutil\n","# Detect if running in Google Colab\n","\n","# Set the environment variable for your GitHub token\n","#os.environ[\"GITHUB_TOKEN\"] =\n","\n","# This cell is for loading data. If your prefer to do this manually, you will need to set base_dir and data_dir separately\n","\n","IN_COLAB = 'google.colab' in sys.modules\n","\n","# Check if running in Google Colab\n","if IN_COLAB:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","\n","    # Set the base directory on Google Drive (no extra folder will be added)\n","    base_dir = \"/content/drive/MyDrive/Bertopic\"\n","    token = os.getenv(\"GITHUB_TOKEN\")\n","    #if os.path.exists(base_dir):\n","     #   shutil.rmtree(base_dir)\n","\n","    #!git clone https://{token}@github.com/UnbrokenCocoon/OCR-evaluation.git \"{base_dir}\"\n","\n","else:\n","    # Set the base directory locally (set this to your local project folder)\n","    base_dir = \"path/to/your/local/project/folder\"\n","\n","    #!git clone https://{token}@github.com/UnbrokenCocoon/OCR-evaluation.git \"{base_dir}\"\n","\n","    # Clone the repository locally\n","\n","\n","# Set the data directory (this assumes you have a 'Data' folder inside the repository)\n","data_dir = os.path.join(base_dir, \"Data\")\n","os.makedirs(data_dir, exist_ok=True)\n","output_dir = os.path.join(base_dir, \"output\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Now data_dir points to the cloned Data folder\n","print(f\"Data folder is located at: {data_dir}\")\n"],"metadata":{"id":"BdwubitUjIFK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# This loads the real data to process\n","import re\n","\n","dir_1 = os.path.join(data_dir,'Batch 4.txt')\n","dir_2 = os.path.join(data_dir,'batches 1 through 3.txt')\n","with open(dir_1) as f:\n","  text_1 = f.read()\n","with open(dir_2) as f:\n","  text_2 = f.read()\n","\n","all_text = text_1 + text_2\n","\n","connectives = r'\\b(?:however|therefore|moreover|but|although|yet|because|so)\\b'\n","# Include major punctuation: comma, semicolon, colon, period, dash, newline, question mark, exclamation\n","split_regex = r'[;,\\.\\?!:\\-\\–\\n]+' + '|' + connectives\n","\n","# Split the text\n","texts = re.split(split_regex, text, flags=re.IGNORECASE)\n","cleaned_texts = [clean_text(t) for t in texts if len(t.strip()) > 0]"],"metadata":{"id":"2Hcib8OlH-WH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_sentences =[]\n","results = []\n","buffer = \"\"\n","for i in cleaned_texts:\n","  buffer += i + \" \"\n","  words = nltk.word_tokenize(buffer)\n","  length = len(words)\n","  if length >= 9:\n","    results.append(length)\n","    buffer.strip()\n","    all_sentences.append(buffer)\n","    buffer = \"\"\n","\n","\n","if buffer.strip():\n","    all_sentences.append(buffer.strip())"],"metadata":{"id":"L1ZzSVuy69TK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now we produce a similar report to confirm everything worked appropriately\n","# You could get too_long lower by chunking once each sentence reaches a length, but this will effect the context of the chunk\n","# This method tolerates some long sentences\n","import numpy as np\n","\n","print(\"Total chunks:\", len(results))\n","print(\"Average length:\", round(np.mean(results),2))\n","print(\"Median length:\", np.median(results))\n","print(\"Max length:\", max(results))\n","print(\"Min length:\", min(results))\n","\n","too_short = sum(r < 9 for r in results)\n","too_long = sum(r > 40 for r in results)\n","print(f\"Chunks < 9 words: {too_short}\")\n","print(f\"Chunks > 20 words: {too_long}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j76sPq7RIqL6","executionInfo":{"status":"ok","timestamp":1746174955617,"user_tz":-60,"elapsed":71,"user":{"displayName":"tom compton","userId":"11608738456980900557"}},"outputId":"0bfaf78e-4bd8-4f44-822b-ff586362a337"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total chunks: 130742\n","Average length: 12.77\n","Median length: 12.0\n","Max length: 54\n","Min length: 9\n","Chunks < 9 words: 0\n","Chunks > 20 words: 31\n"]}]},{"cell_type":"code","source":["# You can use whichever model you prefer\n","# This model is quite good for BERTopic, but may take a while.\n","import sentence_transformers\n","from sentence_transformers import SentenceTransformer\n","\n","# Load https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n","model = SentenceTransformer(\"all-mpnet-base-v2\")\n","embeddings = model.encode(all_sentences, show_progress_bar=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e7c79f659ce94de99c6400ae663641b7","778f96ae504949348dd269472eabc2cb","4f1be87bb28b4e5cb7731207c571664a","dc2aa3e977ee481eb4768bf17463ca8f","59bc5bad310d46e994225735f0095231","88785cb4f569413888f40526ba644c68","6df24f54d8934d3c9b23907ed21cf907","e07f56282d154857a11a98c3244d2d04","d7fb715647f44a2593052f6ec1027f5b","7e59c63c837f443f8037167f6149289a","7fb857c36cac401791f37a0932a51dc2"]},"id":"qfO5cHQjJ75v","executionInfo":{"status":"ok","timestamp":1746456143048,"user_tz":-60,"elapsed":7079352,"user":{"displayName":"tom compton","userId":"11608738456980900557"}},"outputId":"caf58c92-93bf-46d4-c592-51a0d18f0a48"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/3778 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7c79f659ce94de99c6400ae663641b7"}},"metadata":{}}]},{"cell_type":"code","source":["# This double checks everything is equal before saving\n","print(len(embeddings))\n","print(len(all_sentences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UqPFhhGBPJy3","executionInfo":{"status":"ok","timestamp":1746461839264,"user_tz":-60,"elapsed":11,"user":{"displayName":"tom compton","userId":"11608738456980900557"}},"outputId":"b1e1e867-3705-4698-8d0d-ddbec7a0abdc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["120882\n","120882\n"]}]},{"cell_type":"code","source":["import pickle\n","with open(os.path.join(data_dir, 'bc_embedding.pkl'), 'wb') as f:\n","  pickle.dump(embeddings, f)\n","with open(os.path.join(data_dir, 'bc_sentences.pkl'), 'wb') as f:\n","  pickle.dump(all_sentences, f)"],"metadata":{"id":"Tk54ltd9K5CX"},"execution_count":null,"outputs":[]}]}